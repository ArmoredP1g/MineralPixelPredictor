{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from time import sleep\n",
    "from models.attention_series import Grade_regressor\n",
    "import spectral\n",
    "from configs.training_cfg import device\n",
    "import torch\n",
    "import ast\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from spectral import imshow\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "spectral.settings.envi_support_nonlowercase_params = True\n",
    "\n",
    "pre_list = []\n",
    "erro_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\source\\repos\\Pixel-wise-hyperspectral-feature-classification-experiment\\notbooks\\评估脚本.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/source/repos/Pixel-wise-hyperspectral-feature-classification-experiment/notbooks/%E8%AF%84%E4%BC%B0%E8%84%9A%E6%9C%AC.ipynb#W1sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(col):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/source/repos/Pixel-wise-hyperspectral-feature-classification-experiment/notbooks/%E8%AF%84%E4%BC%B0%E8%84%9A%E6%9C%AC.ipynb#W1sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(gts):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/source/repos/Pixel-wise-hyperspectral-feature-classification-experiment/notbooks/%E8%AF%84%E4%BC%B0%E8%84%9A%E6%9C%AC.ipynb#W1sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m         \u001b[39mif\u001b[39;00m mask[r\u001b[39m*\u001b[39m\u001b[39m9\u001b[39m\u001b[39m+\u001b[39m\u001b[39m4\u001b[39m,c\u001b[39m*\u001b[39m\u001b[39m9\u001b[39m\u001b[39m+\u001b[39m\u001b[39m4\u001b[39m]\u001b[39m.\u001b[39mtolist() \u001b[39m==\u001b[39m mask_rgb_values[i]:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/source/repos/Pixel-wise-hyperspectral-feature-classification-experiment/notbooks/%E8%AF%84%E4%BC%B0%E8%84%9A%E6%9C%AC.ipynb#W1sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m             predict_sum[i] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m heat_map[r,c] \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/source/repos/Pixel-wise-hyperspectral-feature-classification-experiment/notbooks/%E8%AF%84%E4%BC%B0%E8%84%9A%E6%9C%AC.ipynb#W1sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m             pixel_count[i] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# 测试样本绝对误差\n",
    "for k in range(1):\n",
    "    model = Grade_regressor().to(device).eval()\n",
    "    model.load_state_dict(torch.load(\"..\\\\ckpt\\\\粉末预训练_11000.pt\".format(k+1)))\n",
    "    result = []\n",
    "    err = 0\n",
    "    err_count = 0 \n",
    "    pool = torch.nn.AvgPool2d(9,9)\n",
    "    mask_rgb_values = [[255,242,0],[34,177,76],[255,0,88],[184,61,186]]\n",
    "\n",
    "    spec_id = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27]    # 选择评估的成像光谱图片编号\n",
    "\n",
    "\n",
    "    for id in spec_id:\n",
    "        img = spectral.envi.open(\"D:\\\\可见光粉末\\\\spectral_data\\{}-RadianceConversion-CorrectFromMeasuredReference.bip.hdr\".format(id))\n",
    "\n",
    "        # 根据模型使用波段选择\n",
    "        # img_data = torch.Tensor(img.asarray()/6000)[:,:,:-4]\n",
    "        img_data = torch.Tensor(img.asarray()/6000)[:,:,:]\n",
    "        mask = np.array(Image.open(\"D:\\\\可见光粉末\\\\spectral_data\\\\{}-RadianceConversion-CorrectFromMeasuredReference.bip.hdr_mask.png\".format(id)))\n",
    "        if mask.shape[2] == 4:\n",
    "            mask = mask[:,:,:-1]\n",
    "        gt_TFe = ast.literal_eval(img.metadata['gt_TFe'])\n",
    "        gt = torch.Tensor(gt_TFe)\n",
    "        gts = gt.__len__()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            img_data = pool(img_data.permute(2,0,1)).permute(1,2,0)\n",
    "            row,col,_ = img_data.shape\n",
    "            heat_map = []\n",
    "\n",
    "            for i in range(row):\n",
    "                heat_map.append(model(img_data[i].to(device)).squeeze(1).unsqueeze(0).to(\"cpu\"))   # 只评估Tfe\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        heat_map = torch.cat(heat_map, dim=0)\n",
    "\n",
    "        predict_sum = torch.zeros(gts)\n",
    "        pixel_count = torch.zeros(gts)/1e5\n",
    "\n",
    "        for r in range(row):\n",
    "            for c in range(col):\n",
    "                for i in range(gts):\n",
    "                    if mask[r*9+4,c*9+4].tolist() == mask_rgb_values[i]:\n",
    "                        predict_sum[i] += heat_map[r,c] \n",
    "                        pixel_count[i] += 1\n",
    "\n",
    "        prediction = predict_sum / pixel_count * 100\n",
    "\n",
    "        err_list = ((prediction-gt)).tolist()\n",
    "        pred_list = (prediction).tolist()\n",
    "        for i in range(err_list.__len__()):\n",
    "            erro_list.append(round(err_list[i],2))\n",
    "            pre_list.append(round(pred_list[i], 2))\n",
    "            \n",
    "\n",
    "    # avg_err = err/(err_count)\n",
    "    # print(\"{}k  avgmse:{}\".format(k+1, avg_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([30.0708, 34.7443])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.51,\n",
       " 1.46,\n",
       " -2.82,\n",
       " nan,\n",
       " -0.31,\n",
       " 2.42,\n",
       " -1.47,\n",
       " nan,\n",
       " -1.17,\n",
       " -0.36,\n",
       " -1.53,\n",
       " nan,\n",
       " 0.85,\n",
       " -3.14,\n",
       " -1.03,\n",
       " nan,\n",
       " 0.05,\n",
       " 3.58,\n",
       " -2.1,\n",
       " nan,\n",
       " 0.44,\n",
       " 1.06,\n",
       " -1.74,\n",
       " nan,\n",
       " -1.31,\n",
       " -2.95,\n",
       " 4.55,\n",
       " nan,\n",
       " 0.22,\n",
       " -2.02,\n",
       " -2.27,\n",
       " nan,\n",
       " -0.34,\n",
       " 4.26,\n",
       " 0.78,\n",
       " nan,\n",
       " 7.21,\n",
       " -6.0,\n",
       " -1.45,\n",
       " nan,\n",
       " 1.98,\n",
       " 3.62,\n",
       " -15.12,\n",
       " nan,\n",
       " -2.57,\n",
       " 0.99,\n",
       " -3.09,\n",
       " nan,\n",
       " 2.75,\n",
       " -1.73,\n",
       " 2.14,\n",
       " nan,\n",
       " 2.98,\n",
       " 10.09,\n",
       " 3.15,\n",
       " nan,\n",
       " -2.08,\n",
       " -1.22,\n",
       " -2.71,\n",
       " nan,\n",
       " 2.29,\n",
       " -3.67,\n",
       " -3.89,\n",
       " nan,\n",
       " -2.25,\n",
       " -2.47,\n",
       " 2.51,\n",
       " nan,\n",
       " -0.1,\n",
       " -2.8,\n",
       " -0.89,\n",
       " nan,\n",
       " -0.27,\n",
       " -5.55,\n",
       " -5.12,\n",
       " nan,\n",
       " -1.92,\n",
       " -1.53,\n",
       " 4.94,\n",
       " nan,\n",
       " -3.29,\n",
       " 9.86,\n",
       " -5.7,\n",
       " nan,\n",
       " 4.33,\n",
       " 1.45,\n",
       " -4.15,\n",
       " nan,\n",
       " 6.25,\n",
       " 1.4,\n",
       " -2.58,\n",
       " nan,\n",
       " 1.98,\n",
       " 0.24,\n",
       " -3.01,\n",
       " nan,\n",
       " 1.26,\n",
       " 3.52,\n",
       " 2.17,\n",
       " nan,\n",
       " -2.92,\n",
       " 5.33,\n",
       " 0.38,\n",
       " nan,\n",
       " 1.37,\n",
       " 5.71]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erro_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[23.16,\n",
       " 16.81,\n",
       " 29.84,\n",
       " nan,\n",
       " 16.41,\n",
       " 33.58,\n",
       " 33.25,\n",
       " nan,\n",
       " 28.78,\n",
       " 23.65,\n",
       " 22.62,\n",
       " nan,\n",
       " 18.86,\n",
       " 32.17,\n",
       " 28.46,\n",
       " nan,\n",
       " 11.45,\n",
       " 30.09,\n",
       " 14.11,\n",
       " nan,\n",
       " 19.77,\n",
       " 12.9,\n",
       " 29.42,\n",
       " nan,\n",
       " 25.54,\n",
       " 32.05,\n",
       " 23.69,\n",
       " nan,\n",
       " 31.81,\n",
       " 33.26,\n",
       " 29.47,\n",
       " nan,\n",
       " 28.73,\n",
       " 33.47,\n",
       " 27.13,\n",
       " nan,\n",
       " 23.65,\n",
       " 18.72,\n",
       " 26.08,\n",
       " nan,\n",
       " 26.06,\n",
       " 27.48,\n",
       " 50.58,\n",
       " nan,\n",
       " 35.38,\n",
       " 34.33,\n",
       " 30.29,\n",
       " nan,\n",
       " 26.35,\n",
       " 23.01,\n",
       " 25.75,\n",
       " nan,\n",
       " 32.88,\n",
       " 31.72,\n",
       " 31.44,\n",
       " nan,\n",
       " 29.17,\n",
       " 29.89,\n",
       " 27.46,\n",
       " nan,\n",
       " 26.6,\n",
       " 31.32,\n",
       " 16.61,\n",
       " nan,\n",
       " 18.96,\n",
       " 30.3,\n",
       " 19.31,\n",
       " nan,\n",
       " 26.16,\n",
       " 30.47,\n",
       " 27.99,\n",
       " nan,\n",
       " 22.65,\n",
       " 29.04,\n",
       " 25.67,\n",
       " nan,\n",
       " 34.01,\n",
       " 35.99,\n",
       " 28.05,\n",
       " nan,\n",
       " 30.02,\n",
       " 29.54,\n",
       " 28.43,\n",
       " nan,\n",
       " 21.28,\n",
       " 19.28,\n",
       " 27.98,\n",
       " nan,\n",
       " 28.4,\n",
       " 26.04,\n",
       " 17.97,\n",
       " nan,\n",
       " 30.4,\n",
       " 22.2,\n",
       " 23.59,\n",
       " nan,\n",
       " 22.73,\n",
       " 24.89,\n",
       " 25.98,\n",
       " nan,\n",
       " 28.63,\n",
       " 22.1,\n",
       " 40.36,\n",
       " nan,\n",
       " 30.07,\n",
       " 34.74]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('VC')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ea0baf3925bd465c6aa19a150df9563e72327e2391888826ad84e3f30d35a1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
