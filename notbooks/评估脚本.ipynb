{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from time import sleep\n",
    "from models.attention_series import Grade_regressor\n",
    "import spectral\n",
    "from configs.training_cfg import device\n",
    "import torch\n",
    "import ast\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from spectral import imshow\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "spectral.settings.envi_support_nonlowercase_params = True\n",
    "\n",
    "pre_list = []\n",
    "erro_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\source\\repos\\Pixel-wise-hyperspectral-feature-classification-experiment\\notbooks\\评估脚本.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/source/repos/Pixel-wise-hyperspectral-feature-classification-experiment/notbooks/%E8%AF%84%E4%BC%B0%E8%84%9A%E6%9C%AC.ipynb#W1sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m                 pixel_count[i] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/source/repos/Pixel-wise-hyperspectral-feature-classification-experiment/notbooks/%E8%AF%84%E4%BC%B0%E8%84%9A%E6%9C%AC.ipynb#W1sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m prediction \u001b[39m=\u001b[39m predict_sum \u001b[39m/\u001b[39m pixel_count \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/source/repos/Pixel-wise-hyperspectral-feature-classification-experiment/notbooks/%E8%AF%84%E4%BC%B0%E8%84%9A%E6%9C%AC.ipynb#W1sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m err_list \u001b[39m=\u001b[39m ((prediction\u001b[39m-\u001b[39;49mgt))\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/source/repos/Pixel-wise-hyperspectral-feature-classification-experiment/notbooks/%E8%AF%84%E4%BC%B0%E8%84%9A%E6%9C%AC.ipynb#W1sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m pred_list \u001b[39m=\u001b[39m (prediction)\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/source/repos/Pixel-wise-hyperspectral-feature-classification-experiment/notbooks/%E8%AF%84%E4%BC%B0%E8%84%9A%E6%9C%AC.ipynb#W1sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(err_list\u001b[39m.\u001b[39m\u001b[39m__len__\u001b[39m()):\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "# 测试样本绝对误差\n",
    "for k in range(1):\n",
    "    model = Grade_regressor().to(device).eval()\n",
    "    model.load_state_dict(torch.load(\"..\\\\ckpt\\\\近红外3_48000.pt\".format(k+1)))\n",
    "    result = []\n",
    "    err = 0\n",
    "    err_count = 0 \n",
    "    pool = torch.nn.AvgPool2d(3,3)\n",
    "    mask_rgb_values = [[255,242,0],[34,177,76],[255,0,88]]\n",
    "\n",
    "    spec_id = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,57,58,59,60,61]    # 选择评估的成像光谱图片编号\n",
    "\n",
    "\n",
    "    for id in spec_id:\n",
    "        img = spectral.envi.open(\"D:\\\\近红外部分\\\\spectral_data\\{}-Radiance From Raw Data-Reflectance from Radiance Data and Measured Reference Spectrum.bip.hdr\".format(id))\n",
    "\n",
    "        # 根据模型使用波段选择\n",
    "        # img_data = torch.Tensor(img.asarray()/6000)[:,:,:-4]\n",
    "        img_data = torch.Tensor(img.asarray()/6000)[:,:,:]\n",
    "        # img_data = pool(img_data.permute(1,2,0)).permute(2,0,1)\n",
    "        mask = np.array(Image.open(\"D:\\\\近红外部分\\\\spectral_data\\\\{}-Radiance From Raw Data-Reflectance from Radiance Data and Measured Reference Spectrum.bip.hdr_mask.png\".format(id)))\n",
    "        if mask.shape[2] == 4:\n",
    "            mask = mask[:,:,:-1]\n",
    "        gt_TFe = ast.literal_eval(img.metadata['gt_TFe'])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            img_data = pool(img_data.permute(2,0,1)).permute(1,2,0)\n",
    "            row,col,_ = img_data.shape\n",
    "            heat_map = []\n",
    "\n",
    "            for i in range(row):\n",
    "                heat_map.append(model(img_data[i].to(device)).squeeze(1).unsqueeze(0).to(\"cpu\"))   # 只评估Tfe\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        heat_map = torch.cat(heat_map, dim=0)\n",
    "\n",
    "        predict_sum = torch.Tensor([0.,0.,0.])\n",
    "        pixel_count = torch.Tensor([0, 0, 0])\n",
    "        gt = torch.Tensor(gt_TFe)\n",
    "\n",
    "        values = [[],[],[]] # 分析数据分布\n",
    "\n",
    "        for r in range(row):\n",
    "            for c in range(col):\n",
    "                for i in range(3):\n",
    "                    if mask[r*3+1,c*3+1].tolist() == mask_rgb_values[i]:\n",
    "                        predict_sum[i] += heat_map[r,c] \n",
    "                        values[i].append(heat_map[r,c])    # 分析数据分布\n",
    "                        pixel_count[i] += 1\n",
    "\n",
    "        prediction = predict_sum / pixel_count * 100\n",
    "\n",
    "        err_list = ((prediction-gt)).tolist()\n",
    "        pred_list = (prediction).tolist()\n",
    "        for i in range(err_list.__len__()):\n",
    "            erro_list.append(round(err_list[i],2))\n",
    "            pre_list.append(round(pred_list[i], 2))\n",
    "            \n",
    "\n",
    "    # avg_err = err/(err_count)\n",
    "    # print(\"{}k  avgmse:{}\".format(k+1, avg_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([25.6812, 21.4506,     nan])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-2.53, -2.32, -4.47]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erro_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[43.78, 54.6, 41.08]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('VC')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ea0baf3925bd465c6aa19a150df9563e72327e2391888826ad84e3f30d35a1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
